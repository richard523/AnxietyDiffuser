{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.1\n"
     ]
    }
   ],
   "source": [
    "! sudo rm -rf /usr/local/bin/ninja\n",
    "! sudo wget -qO /usr/local/bin/ninja.gz https://github.com/ninja-build/ninja/releases/latest/download/ninja-linux.zip\n",
    "! sudo gunzip /usr/local/bin/ninja.gz\n",
    "! sudo chmod a+x /usr/local/bin/ninja\n",
    "! ninja --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting timm\n",
      "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyspng\n",
      "  Downloading pyspng-0.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.5/206.5 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting imageio-ffmpeg\n",
      "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyopengl\n",
      "  Downloading PyOpenGL-3.1.6-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting glfw\n",
      "  Downloading glfw-2.5.9-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (207 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting imgui\n",
      "  Downloading imgui-1.4.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from timm) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.7 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from timm) (1.13.1)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from timm) (0.14.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ftfy) (0.2.5)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pyspng) (1.23.5)\n",
      "Requirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torch>=1.7->timm) (4.4.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (4.63.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (21.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torchvision->timm) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (2.1.1)\n",
      "Installing collected packages: pyopengl, imgui, glfw, pyspng, opencv-contrib-python, imageio-ffmpeg, ftfy, huggingface-hub, timm\n",
      "Successfully installed ftfy-6.1.1 glfw-2.5.9 huggingface-hub-0.13.4 imageio-ffmpeg-0.4.8 imgui-1.4.1 opencv-contrib-python-4.7.0.72 pyopengl-3.1.6 pyspng-0.1.1 timm-0.6.13\n"
     ]
    }
   ],
   "source": [
    "!pip install timm ftfy pyspng imageio-ffmpeg pyopengl glfw imgui opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: opencv-python in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (4.6.0.66)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from opencv-python) (1.23.5)\n",
      "Installing collected packages: opencv-python\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.6.0.66\n",
      "    Uninstalling opencv-python-4.6.0.66:\n",
      "      Successfully uninstalled opencv-python-4.6.0.66\n",
      "Successfully installed opencv-python-4.7.0.72\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: opencv-contrib-python in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from opencv-contrib-python) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade opencv-python\n",
    "! pip install --upgrade opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting en-core-web-lg==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.1/en_core_web_lg-3.4.1-py3-none-any.whl (587.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from en-core-web-lg==3.4.1) (3.4.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.63.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.10.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (65.6.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.1.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.23.5)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.1.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.28.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.4.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (21.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.26.8)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.1.1)\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.4.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
    "#\n",
    "# NVIDIA CORPORATION and its licensors retain all intellectual property\n",
    "# and proprietary rights in and to this software, related documentation\n",
    "# and any modifications thereto.  Any use, reproduction, disclosure or\n",
    "# distribution of this software and related documentation without an express\n",
    "# license agreement from NVIDIA CORPORATION is strictly prohibited.\n",
    "\n",
    "\"\"\"Generate lerp videos using pretrained network pickle.\"\"\"\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import re\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import click\n",
    "import dnnlib\n",
    "import imageio\n",
    "import numpy as np\n",
    "import scipy.interpolate\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import legacy\n",
    "from torch_utils import gen_utils\n",
    "\n",
    "# import cv2\n",
    "#from cv2 import dnn_superres\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "def layout_grid(img, grid_w=None, grid_h=1, float_to_uint8=True, chw_to_hwc=True, to_numpy=True):\n",
    "    batch_size, channels, img_h, img_w = img.shape\n",
    "    if grid_w is None:\n",
    "        grid_w = batch_size // grid_h\n",
    "    assert batch_size == grid_w * grid_h\n",
    "    if float_to_uint8:\n",
    "        img = (img * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "    img = img.reshape(grid_h, grid_w, channels, img_h, img_w)\n",
    "    img = img.permute(2, 0, 3, 1, 4)\n",
    "    img = img.reshape(channels, grid_h * img_h, grid_w * img_w)\n",
    "    if chw_to_hwc:\n",
    "        img = img.permute(1, 2, 0)\n",
    "    if to_numpy:\n",
    "        img = img.cpu().numpy()\n",
    "    return img\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "def gen_interp_video(G, mp4: str, seeds, shuffle_seed=None, w_frames=60*4, kind='cubic', grid_dims=(1,1), num_keyframes=None, wraps=2, truncation_psi=1, device=torch.device('cuda'), centroids_path=None, class_idx=None, **video_kwargs):\n",
    "    grid_w = grid_dims[0]\n",
    "    grid_h = grid_dims[1]\n",
    "\n",
    "    if num_keyframes is None:\n",
    "        if len(seeds) % (grid_w*grid_h) != 0:\n",
    "            raise ValueError('Number of input seeds must be divisible by grid W*H')\n",
    "        num_keyframes = len(seeds) // (grid_w*grid_h)\n",
    "\n",
    "    all_seeds = np.zeros(num_keyframes*grid_h*grid_w, dtype=np.int64)\n",
    "    for idx in range(num_keyframes*grid_h*grid_w):\n",
    "        all_seeds[idx] = seeds[idx % len(seeds)]\n",
    "\n",
    "    if shuffle_seed is not None:\n",
    "        rng = np.random.RandomState(seed=shuffle_seed)\n",
    "        rng.shuffle(all_seeds)\n",
    "    \n",
    "    if class_idx is None:\n",
    "        class_idx = [None] * len(seeds)\n",
    "    elif len(class_idx) == 1:\n",
    "        class_idx = [class_idx] * len(seeds)\n",
    "    assert len(all_seeds) == len(class_idx), \"Seeds and class-idx should have the same length\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    ws = []\n",
    "    for seed, cls in zip(all_seeds, class_idx):\n",
    "        ws.append(\n",
    "            gen_utils.get_w_from_seed(G, 1, device, truncation_psi, seed=seed,\n",
    "                                      centroids_path=centroids_path, class_idx=cls)\n",
    "        )\n",
    "        \n",
    "    ws = torch.cat(ws)\n",
    "    \n",
    "    \n",
    "    \n",
    "    _ = G.synthesis(ws[:1]) # warm up\n",
    "    \n",
    "    ws = ws.reshape(grid_h, grid_w, num_keyframes, *ws.shape[1:])\n",
    "\n",
    "    # Interpolation.\n",
    "    grid = []\n",
    "    for yi in range(grid_h):\n",
    "        row = []\n",
    "        for xi in range(grid_w):\n",
    "            x = np.arange(-num_keyframes * wraps, num_keyframes * (wraps + 1))\n",
    "            y = np.tile(ws[yi][xi].cpu().numpy(), [wraps * 2 + 1, 1, 1])\n",
    "            interp = scipy.interpolate.interp1d(x, y, kind=kind, axis=0)\n",
    "            row.append(interp)\n",
    "        grid.append(row)\n",
    "    \n",
    "    \n",
    "    # Render video.\n",
    "    video_out = imageio.get_writer(mp4, mode='I', fps=30, codec='libx264', **video_kwargs)\n",
    "    for frame_idx in tqdm(range(num_keyframes * w_frames)):\n",
    "        imgs = []\n",
    "        for yi in range(grid_h):\n",
    "            for xi in range(grid_w):\n",
    "                interp = grid[yi][xi]\n",
    "                w = torch.from_numpy(interp(frame_idx / w_frames)).to(device)\n",
    "                img = G.synthesis(ws=w.unsqueeze(0), noise_mode='const')[0]\n",
    "                imgs.append(img)\n",
    "        \n",
    "        image_2d = layout_grid(torch.stack(imgs), grid_w=grid_w, grid_h=grid_h)\n",
    "        \n",
    "        video_out.append_data(image_2d)\n",
    "    video_out.close()\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def parse_range(s: Union[str, List[int]]) -> List[int]:\n",
    "    '''Parse a comma separated list of numbers or ranges and return a list of ints.\n",
    "\n",
    "    Example: '1,2,5-10' returns [1, 2, 5, 6, 7]\n",
    "    '''\n",
    "    if isinstance(s, list): return s\n",
    "    ranges = []\n",
    "    range_re = re.compile(r'^(\\d+)-(\\d+)$')\n",
    "    for p in s.split(','):\n",
    "        m = range_re.match(p)\n",
    "        if m:\n",
    "            ranges.extend(range(int(m.group(1)), int(m.group(2))+1))\n",
    "        else:\n",
    "            ranges.append(int(p))\n",
    "    return ranges\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "def parse_tuple(s: Union[str, Tuple[int,int]]) -> Tuple[int, int]:\n",
    "    '''Parse a 'M,N' or 'MxN' integer tuple.\n",
    "\n",
    "    Example:\n",
    "        '4x2' returns (4,2)\n",
    "        '0,1' returns (0,1)\n",
    "    '''\n",
    "    if isinstance(s, tuple): return s\n",
    "    m = re.match(r'^(\\d+)[x,](\\d+)$', s)\n",
    "    if m:\n",
    "        return (int(m.group(1)), int(m.group(2)))\n",
    "    raise ValueError(f'cannot parse tuple {s}')\n",
    "\n",
    "#----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"./imagenet64.pkl\"...\n"
     ]
    }
   ],
   "source": [
    "model_dir = './imagenet64.pkl'\n",
    "\n",
    "\n",
    "print('Loading networks from \"%s\"...' % model_dir)\n",
    "device = torch.device('cuda')\n",
    "with dnnlib.util.open_url(model_dir) as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].to(device) # type: ignore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import random\n",
    "import math \n",
    "import time\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "\n",
    "labelTxt = [None] * 1000\n",
    "\n",
    "# Using readlines()\n",
    "file1 = open('imagenet_idx2labels.txt', 'r')\n",
    "Lines = file1.readlines()\n",
    " \n",
    "# Strips the newline character\n",
    "for line in Lines:\n",
    "    line = line[1:]\n",
    "    split = line.replace(', ', ',').split(': ')\n",
    "    \n",
    "    class_idx = int(split[0])\n",
    "    \n",
    "    class_split = split[1][1: -3].split(',')\n",
    "    \n",
    "    #print(', '.join(class_split))\n",
    "    \n",
    "    # print(class_idx)\n",
    "    \n",
    "    labelTxt[class_idx] = class_split\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a video 30 seconds long.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [03:40<00:00,  4.08it/s]\n"
     ]
    }
   ],
   "source": [
    "outputLocation = 'lerp.mp4'\n",
    "\n",
    "changeTime = 5\n",
    "framerate = 30\n",
    "amountPerClass = 1\n",
    "\n",
    "def topicToSeed(topic):    \n",
    "    start = time.time()\n",
    "    \n",
    "    closestIndex = 0\n",
    "    sim = 0\n",
    "    \n",
    "    topicNLP = nlp(topic)\n",
    "    \n",
    "    for i in range(len(labelTxt)):\n",
    "        \n",
    "        if labelTxt == None:\n",
    "            continue\n",
    "                \n",
    "        #for item in labelTxt[i]:\n",
    "        \n",
    "        item = labelTxt[i][0]\n",
    "        item_nlp = nlp(item)\n",
    "        cur_sim = topicNLP.similarity(item_nlp)\n",
    "            \n",
    "        if cur_sim > sim:\n",
    "            sim = cur_sim\n",
    "            closestIndex = i\n",
    "    \n",
    "    print(topic, closestIndex,\":\", time.time() - start)\n",
    "    \n",
    "    return closestIndex\n",
    "\n",
    "def recieveInput(videoTopics):\n",
    "\n",
    "    # good_idx = [506, 580, 599, 562, 611, 614, 624, 646, 672, 682, 706, 711, 750, 780, 789, 795, 802, 812, 815, 825, 832 , 835 , 839, 988, 985, 979, 967, 973, 975, 978, 980, 983]\n",
    "    \n",
    "    \n",
    "    class_idx = []\n",
    "    \n",
    "    for topic in videoTopics:\n",
    "        class_idx.append(topicToSeed(topic))\n",
    "    \n",
    "    for _ in range(6):\n",
    "        class_idx.append(good_idx[random.randint(0, len(good_idx))])\n",
    "    \n",
    "    seeds = [random.randint(0,10000) for _ in range(len(class_idx))]\n",
    "    \n",
    "    num_keyframes = len(class_idx)\n",
    "    \n",
    "    w_frames = (framerate * changeTime)  \n",
    "    \n",
    "    print(f\"Making a video {int(num_keyframes * w_frames / framerate)} seconds long.\")\n",
    "    \n",
    "    gen_interp_video(G=G, mp4=outputLocation, bitrate='12M', grid_dims=(1,1), num_keyframes=num_keyframes, w_frames=w_frames, seeds=seeds, shuffle_seed=random.randint(0, 10000), truncation_psi=0.7, centroids_path=None, class_idx=class_idx)\n",
    "\n",
    "    \n",
    "recieveInput(['webs', 'rocket', 'snowboarding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d7b96a25c39fa7937ff3ab94e1dd8c63b93cb924b8f0093093c6266e25a78bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
